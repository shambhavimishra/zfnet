{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prateek\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import SpatialDropout2D, Activation\n",
    "from keras import backend as K\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.utils.data_utils import get_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHANNELS = 3\n",
    "# Number of output masks (1 in case you predict only one type of objects)\n",
    "OUTPUT_MASK_CHANNELS = 1\n",
    "# Pretrained weights\n",
    "ZF_UNET_224_WEIGHT_PATH = 'https://github.com/ZFTurbo/ZF_UNET_224_Pretrained_Model/releases/download/v1.0/zf_unet_224.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    x /= 256\n",
    "    x -= 0.5\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2.0 * intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (intersection + 1.0) / (K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def double_conv_layer(x, size, dropout=0.0, batch_norm=True):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        axis = 1\n",
    "    else:\n",
    "        axis = 3\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(x)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    conv = Conv2D(size, (3, 3), padding='same')(conv)\n",
    "    if batch_norm is True:\n",
    "        conv = BatchNormalization(axis=axis)(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    if dropout > 0:\n",
    "        conv = SpatialDropout2D(dropout)(conv)\n",
    "    return conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZF_UNET_224(dropout_val=0.2, weights=None):\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        inputs = Input((INPUT_CHANNELS, 224, 224))\n",
    "        axis = 1\n",
    "    else:\n",
    "        inputs = Input((224, 224, INPUT_CHANNELS))\n",
    "        axis = 3\n",
    "    filters = 32\n",
    "\n",
    "    conv_224 = double_conv_layer(inputs, filters)\n",
    "    pool_112 = MaxPooling2D(pool_size=(2, 2))(conv_224)\n",
    "\n",
    "    conv_112 = double_conv_layer(pool_112, 2*filters)\n",
    "    pool_56 = MaxPooling2D(pool_size=(2, 2))(conv_112)\n",
    "\n",
    "    conv_56 = double_conv_layer(pool_56, 4*filters)\n",
    "    pool_28 = MaxPooling2D(pool_size=(2, 2))(conv_56)\n",
    "\n",
    "    conv_28 = double_conv_layer(pool_28, 8*filters)\n",
    "    pool_14 = MaxPooling2D(pool_size=(2, 2))(conv_28)\n",
    "\n",
    "    conv_14 = double_conv_layer(pool_14, 16*filters)\n",
    "    pool_7 = MaxPooling2D(pool_size=(2, 2))(conv_14)\n",
    "\n",
    "    conv_7 = double_conv_layer(pool_7, 32*filters)\n",
    "\n",
    "    up_14 = concatenate([UpSampling2D(size=(2, 2))(conv_7), conv_14], axis=axis)\n",
    "    up_conv_14 = double_conv_layer(up_14, 16*filters)\n",
    "\n",
    "    up_28 = concatenate([UpSampling2D(size=(2, 2))(up_conv_14), conv_28], axis=axis)\n",
    "    up_conv_28 = double_conv_layer(up_28, 8*filters)\n",
    "\n",
    "    up_56 = concatenate([UpSampling2D(size=(2, 2))(up_conv_28), conv_56], axis=axis)\n",
    "    up_conv_56 = double_conv_layer(up_56, 4*filters)\n",
    "\n",
    "    up_112 = concatenate([UpSampling2D(size=(2, 2))(up_conv_56), conv_112], axis=axis)\n",
    "    up_conv_112 = double_conv_layer(up_112, 2*filters)\n",
    "\n",
    "    up_224 = concatenate([UpSampling2D(size=(2, 2))(up_conv_112), conv_224], axis=axis)\n",
    "    up_conv_224 = double_conv_layer(up_224, filters, dropout_val)\n",
    "\n",
    "    conv_final = Conv2D(OUTPUT_MASK_CHANNELS, (1, 1))(up_conv_224)\n",
    "    conv_final = Activation('sigmoid')(conv_final)\n",
    "\n",
    "    model = Model(inputs, conv_final, name=\"ZF_UNET_224\")\n",
    "\n",
    "    if weights == 'generator' and axis == 3 and INPUT_CHANNELS == 3 and OUTPUT_MASK_CHANNELS == 1:\n",
    "        weights_path = get_file(\n",
    "            'zf_unet_224_weights_tf_dim_ordering_tf_generator.h5',\n",
    "            ZF_UNET_224_WEIGHT_PATH,\n",
    "            cache_subdir='models',\n",
    "            file_hash='203146f209baf34ac0d793e1691f1ab7')\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import __version__\n",
    "from zf_unet_224_model import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.9.0\n",
      "Keras version 2.2.2\n",
      "Dim ordering: tf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prateek\\Anaconda3\\lib\\site-packages\\keras\\callbacks.py:999: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "  warnings.warn('`epsilon` argument is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def gen_random_image():\n",
    "    img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "    mask = np.zeros((224, 224), dtype=np.uint8)\n",
    "\n",
    "    # Background\n",
    "    dark_color0 = random.randint(0, 100)\n",
    "    dark_color1 = random.randint(0, 100)\n",
    "    dark_color2 = random.randint(0, 100)\n",
    "    img[:, :, 0] = dark_color0\n",
    "    img[:, :, 1] = dark_color1\n",
    "    img[:, :, 2] = dark_color2\n",
    "\n",
    "    # Object\n",
    "    light_color0 = random.randint(dark_color0+1, 255)\n",
    "    light_color1 = random.randint(dark_color1+1, 255)\n",
    "    light_color2 = random.randint(dark_color2+1, 255)\n",
    "    center_0 = random.randint(0, 224)\n",
    "    center_1 = random.randint(0, 224)\n",
    "    r1 = random.randint(10, 56)\n",
    "    r2 = random.randint(10, 56)\n",
    "    cv2.ellipse(img, (center_0, center_1), (r1, r2), 0, 0, 360, (light_color0, light_color1, light_color2), -1)\n",
    "    cv2.ellipse(mask, (center_0, center_1), (r1, r2), 0, 0, 360, 255, -1)\n",
    "\n",
    "    # White noise\n",
    "    density = random.uniform(0, 0.1)\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            if random.random() < density:\n",
    "                img[i, j, 0] = random.randint(0, 255)\n",
    "                img[i, j, 1] = random.randint(0, 255)\n",
    "                img[i, j, 2] = random.randint(0, 255)\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "def batch_generator(batch_size):\n",
    "    while True:\n",
    "        image_list = []\n",
    "        mask_list = []\n",
    "        for i in range(batch_size):\n",
    "            img, mask = gen_random_image()\n",
    "            image_list.append(img)\n",
    "            mask_list.append([mask])\n",
    "\n",
    "        image_list = np.array(image_list, dtype=np.float32)\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            image_list = image_list.transpose((0, 3, 1, 2))\n",
    "        image_list = preprocess_input(image_list)\n",
    "        mask_list = np.array(mask_list, dtype=np.float32)\n",
    "        mask_list /= 255.0\n",
    "        yield image_list, mask_list\n",
    "\n",
    "\n",
    "def train_unet():\n",
    "    out_model_path = 'zf_unet_224.h5'\n",
    "    epochs = 10\n",
    "    patience = 20\n",
    "    batch_size = 16\n",
    "    optim_type = 'SGD'\n",
    "    learning_rate = 0.001\n",
    "    model = ZF_UNET_224()\n",
    "    if os.path.isfile(out_model_path):\n",
    "        model.load_weights(out_model_path)\n",
    "\n",
    "    if optim_type == 'SGD':\n",
    "        optim = SGD(lr=learning_rate, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    else:\n",
    "        optim = Adam(lr=learning_rate)\n",
    "    model.compile(optimizer=optim, loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-9, epsilon=0.00001, verbose=1, mode='min'),\n",
    "        # EarlyStopping(monitor='val_loss', patience=patience, verbose=0),\n",
    "        ModelCheckpoint('zf_unet_224_temp.h5', monitor='val_loss', save_best_only=True, verbose=0),\n",
    "    ]\n",
    "\n",
    "    print('Start training...')\n",
    "    history = model.fit_generator(\n",
    "        generator=batch_generator(batch_size),\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=10,\n",
    "        validation_data=batch_generator(batch_size),\n",
    "        validation_steps=10,\n",
    "        verbose=2,\n",
    "        callbacks=callbacks)\n",
    "\n",
    "    model.save_weights(out_model_path)\n",
    "    pd.DataFrame(history.history).to_csv('zf_unet_224_train.csv', index=False)\n",
    "    print('Training is finished (weights zf_unet_224.h5 and log zf_unet_224_train.csv are generated )...')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if K.backend() == 'tensorflow':\n",
    "        try:\n",
    "            from tensorflow import __version__ as __tensorflow_version__\n",
    "            print('Tensorflow version: {}'.format(__tensorflow_version__))\n",
    "        except:\n",
    "            print('Tensorflow is unavailable...')\n",
    "    else:\n",
    "        try:\n",
    "            from theano.version import version as __theano_version__\n",
    "            print('Theano version: {}'.format(__theano_version__))\n",
    "        except:\n",
    "            print('Theano is unavailable...')\n",
    "    print('Keras version {}'.format(__version__))\n",
    "    print('Dim ordering:', K.image_dim_ordering())\n",
    "    train_unet()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
